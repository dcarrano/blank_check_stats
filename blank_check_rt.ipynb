{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas & general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from collections import defaultdict \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "current_year = datetime.date.today().year\n",
    "\n",
    "base_search = 'https://www.rottentomatoes.com/'\n",
    "\n",
    "director_search = f'{base_search}celebrity/'\n",
    "franchise_search = f'{base_search}franchise/'\n",
    "general_search = f'{base_search}search?search='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to change lists of directors/franchises to more URL-friendly form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def urlify_list(my_list):\n",
    "\n",
    "    my_dict = defaultdict(dict)\n",
    "\n",
    "    for item in my_list:\n",
    "       \n",
    "       my_dict[item]['url_friendly_name'] = ' '.join(item.lower().replace('-', '').replace('.', '').split()).replace(' ', '_')\n",
    "\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to pass web page to main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(subject, **kwargs):\n",
    "\n",
    "    uri = subject['url_friendly_name']\n",
    "\n",
    "    if kwargs['type'] == 'director':\n",
    "\n",
    "        url = f'{director_search}{uri}'\n",
    "\n",
    "    elif kwargs['type'] == 'franchise':\n",
    "\n",
    "        url = f'{franchise_search}{uri}'\n",
    "\n",
    "    page = requests.get(url)\n",
    "\n",
    "    return BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of directors; modify as needed\n",
    "\n",
    "directors = ['George Lucas', 'M. Night Shyamalan', 'Lana Wachowski', 'Cameron Crowe', 'James Cameron', 'Steven Spielberg',\n",
    "             'Christopher Nolan', 'Kathryn Bigelow', 'Paul Verhoeven', 'James L. Brooks', 'Brad Bird', 'Genndy Tartakovsky', \n",
    "             'Ang Lee', 'Bradley Cooper', 'Nancy Meyers', 'Tim Burton', 'Michael Mann', 'Hayao Miyazaki', 'Jonathan Demme', \n",
    "             'George Miller', 'Nora Ephron', 'Gina Prince-Bythewood', 'Robert Zemeckis', 'John Musker', 'Elaine May', \n",
    "             'Joseph Gordon-Levitt', 'John Singleton', 'John Carpenter', 'Jane Campion', 'Sam Raimi', 'Bob Fosse',\n",
    "             'Stanley Kubrick', 'Henry Selick', 'Danny Boyle', 'Buster Keaton', 'Park Chan Wook', 'David Fincher',\n",
    "             'Barbra Streisand', 'John McTiernan']\n",
    "\n",
    "\n",
    "# Add to this dictionary if the miniseries is better referred to by a name other than the director's\n",
    "\n",
    "aliases = {'Lana Wachowski': 'The Wachowskis',\n",
    "            'John Musker': 'Musker/Clements'}\n",
    "\n",
    "\n",
    "director_dict = urlify_list(directors)\n",
    "\n",
    "\n",
    "# Start/end dates that the pod covered, if applicable\n",
    "\n",
    "director_start_dates = {'George Lucas' : 1977,\n",
    "                        'Steven Spielberg': 1997,\n",
    "                        'Paul Verhoeven': 1985,\n",
    "                        'Buster Keaton': 1923}\n",
    "\n",
    "director_end_dates = {'Buster Keaton' : 1929}\n",
    "\n",
    "\n",
    "# For some very weird reason, RT refers to John Carpenter by his actor alias \"Rip Haight\"\n",
    "\n",
    "director_dict['John Carpenter']['url_friendly_name'] = 'rip_haight'\n",
    "\n",
    "\n",
    "# Results dictionary we're about to use\n",
    "\n",
    "def dd():\n",
    "    \n",
    "    return defaultdict(dict)\n",
    "\n",
    "director_results = defaultdict(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in director_dict.items():\n",
    "\n",
    "    if key not in director_results:\n",
    "\n",
    "        soup = get_soup(val, type = 'director')\n",
    "\n",
    "        movie_rows = soup.find_all('tr', {'data-qa' : 'celebrity-filmography-movies-trow'}) \n",
    "\n",
    "        for row in movie_rows:\n",
    "\n",
    "              this_movie_title = row['data-title']\n",
    "\n",
    "              this_movie_year = int(row['data-year'])\n",
    "\n",
    "              this_movie_credit = row.find('td', {'class' : 'celebrity-filmography__credits'}).text\n",
    "\n",
    "              this_movie_rt = row.find('span', attrs = {'class' : 'label', 'data-tomatometer': True})\n",
    "\n",
    "              if (this_movie_rt is not None) & ('Director' in this_movie_credit) & (this_movie_year >= director_start_dates.get(key, 0)) & (this_movie_year <= director_end_dates.get(key, current_year)):\n",
    "\n",
    "                      director_results[key][this_movie_title]['Year'] = this_movie_year\n",
    "                      director_results[key][this_movie_title]['RT'] = this_movie_rt['data-tomatometer']\n",
    "                      print(this_movie_title, this_movie_year, this_movie_rt['data-tomatometer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to convert scraped dictionary to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dict_to_df(my_dict):\n",
    "\n",
    "    return pd.concat({\n",
    "        k: pd.DataFrame.from_dict(v, 'index') for k, v in my_dict.items()\n",
    "    }, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make director dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directors_df = nested_dict_to_df(director_results).rename_axis(['Subject', 'Title']).reset_index()\n",
    "\n",
    "\n",
    "# List of movies that were skipped; modify as needed\n",
    "\n",
    "director_manual_drops = ['Pearl Jam Twenty',\n",
    "                         'Quay',\n",
    "                         'Black Book',\n",
    "                         \"Tim Burton's Corpse Bride\",\n",
    "                         'Frankenweenie',\n",
    "                         'Swimming to Cambodia',\n",
    "                         'Enzo Avitabile Music Life',\n",
    "                         'Neil Young Journeys',\n",
    "                         'Neil Young Trunk Show',\n",
    "                         'Jimmy Carter: Man From Plains',\n",
    "                         'Neil Young: Heart of Gold',\n",
    "                         'The Agronomist',\n",
    "                         'Storefront Hitchcock',\n",
    "                         'Disappearing Acts',\n",
    "                         \"Someone's Watching Me!\",\n",
    "                         'Elvis',\n",
    "                         'Body Bags',\n",
    "                         'Three... Extremes',\n",
    "                         'Full Frontal']\n",
    "\n",
    "# Drop skipped movies\n",
    "\n",
    "directors_df = directors_df[~directors_df['Title'].isin(director_manual_drops)]\n",
    "\n",
    "\n",
    "directors_df['Feed'] = 'Main Feed'\n",
    "\n",
    "directors_df['Subject'] = [aliases.get(x, x) for x in directors_df['Subject']]\n",
    "\n",
    "\n",
    "directors_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Franchises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of franchises; modify as needed. Note that the RT franchise pages are very random\n",
    "# (e.g. no James Bond or Star Wars??), so check to see what exists before adding. \n",
    "# They also often are inaccessible for no apparent reason. Pay attention when you run the next cell. \n",
    "# It will interrupt if it can't access the franchise page. You may need to re-run it until it goes.\n",
    "\n",
    "franchises = ['Marvel Cinematic Universe', 'Mission Impossible', 'Alien', 'Star Trek', 'Ghostbusters', \n",
    "            'Men in Black', 'Planet of the Apes', 'Oceans', 'Austin Powers', 'Terminator']\n",
    "\n",
    "             \n",
    "# Start/end dates that the pod covered, if applicable\n",
    "\n",
    "franchise_start_dates = {}\n",
    "\n",
    "franchise_end_dates = {'Marvel Cinematic Universe' : 2019,\n",
    "                        'Mission Impossible' : 2018,\n",
    "                        'Star Trek' : 1991, \n",
    "                        'Planet of the Apes' : 1973}\n",
    "\n",
    "\n",
    "franchise_dict = urlify_list(franchises)\n",
    "\n",
    "\n",
    "# Results dictionary we're about to use\n",
    "\n",
    "franchise_results = defaultdict(dd)\n",
    "\n",
    "\n",
    "franchise_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in franchise_dict.items():\n",
    "\n",
    "    if key not in franchise_results:\n",
    "\n",
    "        soup = get_soup(val, type = 'franchise')\n",
    "\n",
    "        movie_list_items = soup.find_all('li', {'data-franchise-type' : 'Movie'})\n",
    "\n",
    "        if not movie_list_items:\n",
    "\n",
    "            input('ERROR! RT franchise page being weird! Re-run this cell until it works!')\n",
    "\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            \n",
    "            for item in movie_list_items:\n",
    "\n",
    "                this_movie_year = int(item.find('span', {'data-qa' : True}).text[1:-1])\n",
    "\n",
    "                this_movie_title = item.find('a', {'data-qa' : True}).text.strip()\n",
    "\n",
    "\n",
    "                if (this_movie_title == \"Ocean's Eleven\") | (this_movie_title == 'Ghostbusters'): # Same title in same franchise!\n",
    "\n",
    "                    this_movie_title = item.find('a', {'data-qa' : True}).text.strip() + ' (' + str(this_movie_year) + ')'\n",
    "\n",
    "\n",
    "                this_movie_rt = item.find('strong', {'data-qa': 'franchise-media-tomatometer'})\n",
    "                \n",
    "\n",
    "                if (this_movie_rt is not None) & (this_movie_year >= franchise_start_dates.get(key, 0)) & (this_movie_year <= franchise_end_dates.get(key,  current_year)):\n",
    "\n",
    "                    franchise_results[key][this_movie_title]['Year'] = this_movie_year\n",
    "\n",
    "                    franchise_results[key][this_movie_title]['RT'] = this_movie_rt.text[0:-1]\n",
    "\n",
    "                    print(this_movie_title, this_movie_year, this_movie_rt.text[0:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make franchise dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "franchises_df = nested_dict_to_df(franchise_results).rename_axis(['Subject', 'Title']).reset_index()\n",
    "\n",
    "\n",
    "# List of movies that were skipped; modify as needed\n",
    "\n",
    "franchise_manual_drops = []\n",
    "\n",
    "\n",
    "# Drop skipped movies\n",
    "\n",
    "franchises_df = franchises_df[~franchises_df['Title'].isin(franchise_manual_drops)]\n",
    "\n",
    "\n",
    "franchises_df['Feed'] = 'Patreon'\n",
    "\n",
    "\n",
    "franchises_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other movies covered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in spreadsheet\n",
    "\n",
    "da_moviesh = pd.read_excel(f'blank_check_addl.ods', sheet_name = 'Sheet1', dtype = {'Year' : 'Int64'}).reset_index()\n",
    "\n",
    "\n",
    "# Unfortunately, I don't believe RT has \"advanced\" search options.\n",
    "# It's possible that the movie you want won't be on the first page of results.\n",
    "# There are also a couple of examples of movies in the RT database that have both the same year \n",
    "# and the same title. Rather than having to do a whole bunch more programming to handle a handful of cases,\n",
    "# it's easier to simply add an actor name to the movies that have these issues. \n",
    "# If you see such issues, edit the dictionary below accordingly.\n",
    "\n",
    "narrow_result = {'Justice League' : 'Justice League Affleck',\n",
    "                    'Whisper of the Heart' : 'Whisper of the Heart Snow',\n",
    "                    'Babe' : 'Babe Cromwell',\n",
    "                    'Aladdin and the King of Thieves' : 'Aladdin and the King of Thieves Bettin',\n",
    "                    'The Lego Batman Movie' : 'The Lego Batman Movie Arnett'}\n",
    "\n",
    "da_moviesh['url_friendly_name'] = [narrow_result.get(x, x) for x in da_moviesh['Title']]\n",
    "\n",
    "\n",
    "# \"The Mummy\" is particularly annoying because there are two covered movies named that,\n",
    "# and only the lousy 2017 version shows up on the first page of results.\n",
    "\n",
    "da_moviesh.loc[(da_moviesh['Title'] == 'The Mummy') & (da_moviesh['Year'] == 1999), 'url_friendly_name'] = 'The Mummy Fraser'\n",
    "\n",
    "\n",
    "# Because it's possible a title can look like an integer (e.g. \"2010\"), we have to make sure Pandas knows the column\n",
    "# we just made is a string. We also need to convert ampersands so the search can understand them.\n",
    "\n",
    "da_moviesh['url_friendly_name'] = da_moviesh['url_friendly_name'].astype(str)\n",
    "\n",
    "da_moviesh['url_friendly_name'] = da_moviesh['url_friendly_name'].str.lower().str.replace('&', '%26')\n",
    "\n",
    "\n",
    "# Results list we're about to use\n",
    "\n",
    "moviesh_results = []\n",
    "\n",
    "\n",
    "da_moviesh.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_index, this_title, this_year, this_search_name in zip(\n",
    "    da_moviesh['index'], da_moviesh['Title'], \n",
    "    da_moviesh['Year'], da_moviesh['url_friendly_name']):\n",
    "\n",
    "    if this_index not in moviesh_results:\n",
    "\n",
    "        url = f'{general_search}{this_search_name}'\n",
    "\n",
    "        print(f'{this_title}, Year Input: {this_year},', end = ' ')\n",
    "\n",
    "        page = requests.get(url)\n",
    "\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        movies_only = soup.find('search-page-result', type = 'movie')\n",
    "\n",
    "        movie_rows = movies_only.find_all('search-page-media-row')\n",
    "\n",
    "        results_titles = []\n",
    "\n",
    "        results_years = []\n",
    "        \n",
    "        results_tomatometers = []\n",
    "        \n",
    "\n",
    "        for row in movie_rows:\n",
    "\n",
    "            if len(str(row['tomatometerscore'])) > 0: # Skip rows without RT scores\n",
    "\n",
    "                results_titles.append(row.find('img')['alt'])\n",
    "\n",
    "                results_years.append(row['releaseyear'])\n",
    "\n",
    "                results_tomatometers.append(row['tomatometerscore'])\n",
    "\n",
    "\n",
    "        df = pd.DataFrame({'result_title': results_titles, 'result_year': results_years, 'RT': results_tomatometers})    \n",
    "\n",
    "\n",
    "        if pd.isna(this_year):\n",
    "\n",
    "            df = df[df['result_title'].str.upper() == str(this_title).upper()]\n",
    "\n",
    "        else:\n",
    "\n",
    "            df = df[(df['result_title'].str.upper() == str(this_title).upper()) & (df['result_year'] == str(this_year))]\n",
    "\n",
    "        \n",
    "        # If adding to spreadsheet, be sure to check the output to see if there are match problems.\n",
    "\n",
    "        if len(df.index) == 0:\n",
    "\n",
    "            print('WARNING: No matches!')\n",
    "\n",
    "        elif len(df.index) > 1:\n",
    "\n",
    "            print(f'WARNING: {len(df.index)} matches!')\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(f\"Year Found: {df.iloc[0]['result_year']}, RT: {df.iloc[0]['RT']}\")\n",
    "\n",
    "\n",
    "        moviesh_results = moviesh_results + df.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make other movie dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesh_results_df = pd.DataFrame(moviesh_results).reset_index()\n",
    "\n",
    "\n",
    "moviesh_df = pd.merge(da_moviesh,\n",
    "                    moviesh_results_df,\n",
    "                     on = 'index')\n",
    "\n",
    "moviesh_df['Year'] = moviesh_df['result_year'].astype('int64')\n",
    "\n",
    "moviesh_df = moviesh_df.drop(['index', 'result_title', 'url_friendly_name', 'result_year'], axis = 1)\n",
    "\n",
    "\n",
    "moviesh_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.concat([directors_df, franchises_df, moviesh_df], ignore_index = True)\n",
    "\n",
    "output = output[['Feed', 'Subject', 'Title', 'Year', 'RT']]\n",
    "\n",
    "output = output.sort_values(by = ['Feed', 'Subject', 'Year'])\n",
    "\n",
    "output.to_csv('blank_check_rt.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
